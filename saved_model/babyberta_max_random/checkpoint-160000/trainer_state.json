{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.196806392706603,
  "eval_steps": 500,
  "global_step": 160000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "grad_norm": 4.53947114944458,
      "learning_rate": 4.166666666666667e-06,
      "loss": 8.7232,
      "step": 1000
    },
    {
      "epoch": 0.03,
      "grad_norm": 5.974277496337891,
      "learning_rate": 8.333333333333334e-06,
      "loss": 7.7915,
      "step": 2000
    },
    {
      "epoch": 0.04,
      "grad_norm": 3.6817626953125,
      "learning_rate": 1.25e-05,
      "loss": 6.8553,
      "step": 3000
    },
    {
      "epoch": 0.05,
      "grad_norm": 3.784738063812256,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 6.1556,
      "step": 4000
    },
    {
      "epoch": 0.07,
      "grad_norm": 3.6709887981414795,
      "learning_rate": 2.0833333333333336e-05,
      "loss": 5.8154,
      "step": 5000
    },
    {
      "epoch": 0.08,
      "grad_norm": 4.614590167999268,
      "learning_rate": 2.5e-05,
      "loss": 5.5497,
      "step": 6000
    },
    {
      "epoch": 0.1,
      "grad_norm": 5.388477802276611,
      "learning_rate": 2.916666666666667e-05,
      "loss": 5.4343,
      "step": 7000
    },
    {
      "epoch": 0.11,
      "grad_norm": 6.438815116882324,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 5.3317,
      "step": 8000
    },
    {
      "epoch": 0.12,
      "grad_norm": 6.993662357330322,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 5.2353,
      "step": 9000
    },
    {
      "epoch": 0.14,
      "grad_norm": 5.300751209259033,
      "learning_rate": 4.166666666666667e-05,
      "loss": 5.1202,
      "step": 10000
    },
    {
      "epoch": 0.15,
      "grad_norm": 5.019444465637207,
      "learning_rate": 4.5833333333333334e-05,
      "loss": 5.0339,
      "step": 11000
    },
    {
      "epoch": 0.16,
      "grad_norm": 7.6225738525390625,
      "learning_rate": 5e-05,
      "loss": 4.9115,
      "step": 12000
    },
    {
      "epoch": 0.18,
      "grad_norm": 6.045605182647705,
      "learning_rate": 5.4166666666666664e-05,
      "loss": 4.8319,
      "step": 13000
    },
    {
      "epoch": 0.19,
      "grad_norm": 7.042829513549805,
      "learning_rate": 5.833333333333334e-05,
      "loss": 4.7608,
      "step": 14000
    },
    {
      "epoch": 0.21,
      "grad_norm": 7.25803804397583,
      "learning_rate": 6.25e-05,
      "loss": 4.7049,
      "step": 15000
    },
    {
      "epoch": 0.22,
      "grad_norm": 8.142138481140137,
      "learning_rate": 6.666666666666667e-05,
      "loss": 4.5734,
      "step": 16000
    },
    {
      "epoch": 0.23,
      "grad_norm": 9.89026165008545,
      "learning_rate": 7.083333333333334e-05,
      "loss": 4.4793,
      "step": 17000
    },
    {
      "epoch": 0.25,
      "grad_norm": 7.583662033081055,
      "learning_rate": 7.500000000000001e-05,
      "loss": 4.4328,
      "step": 18000
    },
    {
      "epoch": 0.26,
      "grad_norm": 10.411828994750977,
      "learning_rate": 7.916666666666666e-05,
      "loss": 4.324,
      "step": 19000
    },
    {
      "epoch": 0.27,
      "grad_norm": 7.627639293670654,
      "learning_rate": 8.333333333333334e-05,
      "loss": 4.2988,
      "step": 20000
    },
    {
      "epoch": 0.29,
      "grad_norm": 8.928314208984375,
      "learning_rate": 8.75e-05,
      "loss": 4.2385,
      "step": 21000
    },
    {
      "epoch": 0.3,
      "grad_norm": 11.6528959274292,
      "learning_rate": 9.166666666666667e-05,
      "loss": 4.1351,
      "step": 22000
    },
    {
      "epoch": 0.32,
      "grad_norm": 7.640802383422852,
      "learning_rate": 9.583333333333334e-05,
      "loss": 4.089,
      "step": 23000
    },
    {
      "epoch": 0.33,
      "grad_norm": 6.80726432800293,
      "learning_rate": 0.0001,
      "loss": 4.0443,
      "step": 24000
    },
    {
      "epoch": 0.34,
      "grad_norm": 9.07547664642334,
      "learning_rate": 9.926470588235295e-05,
      "loss": 3.9371,
      "step": 25000
    },
    {
      "epoch": 0.36,
      "grad_norm": 9.961650848388672,
      "learning_rate": 9.852941176470589e-05,
      "loss": 3.9111,
      "step": 26000
    },
    {
      "epoch": 0.37,
      "grad_norm": 8.671547889709473,
      "learning_rate": 9.779411764705882e-05,
      "loss": 3.8827,
      "step": 27000
    },
    {
      "epoch": 0.38,
      "grad_norm": 10.314775466918945,
      "learning_rate": 9.705882352941177e-05,
      "loss": 3.8194,
      "step": 28000
    },
    {
      "epoch": 0.4,
      "grad_norm": 6.962604522705078,
      "learning_rate": 9.632352941176472e-05,
      "loss": 3.7628,
      "step": 29000
    },
    {
      "epoch": 0.41,
      "grad_norm": 7.898293495178223,
      "learning_rate": 9.558823529411765e-05,
      "loss": 3.7991,
      "step": 30000
    },
    {
      "epoch": 0.43,
      "grad_norm": 7.070078372955322,
      "learning_rate": 9.485294117647059e-05,
      "loss": 3.7372,
      "step": 31000
    },
    {
      "epoch": 0.44,
      "grad_norm": 8.122954368591309,
      "learning_rate": 9.411764705882353e-05,
      "loss": 3.6593,
      "step": 32000
    },
    {
      "epoch": 0.45,
      "grad_norm": 8.077292442321777,
      "learning_rate": 9.338235294117648e-05,
      "loss": 3.61,
      "step": 33000
    },
    {
      "epoch": 0.47,
      "grad_norm": 8.725641250610352,
      "learning_rate": 9.264705882352942e-05,
      "loss": 3.6101,
      "step": 34000
    },
    {
      "epoch": 0.48,
      "grad_norm": 7.663029670715332,
      "learning_rate": 9.191176470588235e-05,
      "loss": 3.5436,
      "step": 35000
    },
    {
      "epoch": 0.49,
      "grad_norm": 9.227205276489258,
      "learning_rate": 9.11764705882353e-05,
      "loss": 3.5648,
      "step": 36000
    },
    {
      "epoch": 0.51,
      "grad_norm": 6.092819690704346,
      "learning_rate": 9.044117647058823e-05,
      "loss": 3.5009,
      "step": 37000
    },
    {
      "epoch": 0.52,
      "grad_norm": 7.716342926025391,
      "learning_rate": 8.970588235294118e-05,
      "loss": 3.5013,
      "step": 38000
    },
    {
      "epoch": 0.54,
      "grad_norm": 7.905060768127441,
      "learning_rate": 8.897058823529412e-05,
      "loss": 3.4895,
      "step": 39000
    },
    {
      "epoch": 0.55,
      "grad_norm": 10.920439720153809,
      "learning_rate": 8.823529411764706e-05,
      "loss": 3.4485,
      "step": 40000
    },
    {
      "epoch": 0.56,
      "grad_norm": 8.34512996673584,
      "learning_rate": 8.75e-05,
      "loss": 3.4166,
      "step": 41000
    },
    {
      "epoch": 0.58,
      "grad_norm": 9.834257125854492,
      "learning_rate": 8.676470588235295e-05,
      "loss": 3.4002,
      "step": 42000
    },
    {
      "epoch": 0.59,
      "grad_norm": 8.60045337677002,
      "learning_rate": 8.60294117647059e-05,
      "loss": 3.3568,
      "step": 43000
    },
    {
      "epoch": 0.6,
      "grad_norm": 9.298917770385742,
      "learning_rate": 8.529411764705883e-05,
      "loss": 3.3168,
      "step": 44000
    },
    {
      "epoch": 0.62,
      "grad_norm": 6.751192569732666,
      "learning_rate": 8.455882352941176e-05,
      "loss": 3.3387,
      "step": 45000
    },
    {
      "epoch": 0.63,
      "grad_norm": 9.785972595214844,
      "learning_rate": 8.382352941176471e-05,
      "loss": 3.2616,
      "step": 46000
    },
    {
      "epoch": 0.65,
      "grad_norm": 8.10424518585205,
      "learning_rate": 8.308823529411766e-05,
      "loss": 3.2802,
      "step": 47000
    },
    {
      "epoch": 0.66,
      "grad_norm": 8.248773574829102,
      "learning_rate": 8.23529411764706e-05,
      "loss": 3.2835,
      "step": 48000
    },
    {
      "epoch": 0.67,
      "grad_norm": 10.716604232788086,
      "learning_rate": 8.161764705882353e-05,
      "loss": 3.2149,
      "step": 49000
    },
    {
      "epoch": 0.69,
      "grad_norm": 9.649662971496582,
      "learning_rate": 8.088235294117648e-05,
      "loss": 3.2306,
      "step": 50000
    },
    {
      "epoch": 0.7,
      "grad_norm": 7.5591721534729,
      "learning_rate": 8.014705882352943e-05,
      "loss": 3.2414,
      "step": 51000
    },
    {
      "epoch": 0.71,
      "grad_norm": 8.847742080688477,
      "learning_rate": 7.941176470588235e-05,
      "loss": 3.1814,
      "step": 52000
    },
    {
      "epoch": 0.73,
      "grad_norm": 14.24669075012207,
      "learning_rate": 7.86764705882353e-05,
      "loss": 3.1715,
      "step": 53000
    },
    {
      "epoch": 0.74,
      "grad_norm": 6.951420783996582,
      "learning_rate": 7.794117647058824e-05,
      "loss": 3.1922,
      "step": 54000
    },
    {
      "epoch": 0.76,
      "grad_norm": 8.163068771362305,
      "learning_rate": 7.720588235294119e-05,
      "loss": 3.135,
      "step": 55000
    },
    {
      "epoch": 0.77,
      "grad_norm": 9.151640892028809,
      "learning_rate": 7.647058823529411e-05,
      "loss": 3.1501,
      "step": 56000
    },
    {
      "epoch": 0.78,
      "grad_norm": 8.025607109069824,
      "learning_rate": 7.573529411764706e-05,
      "loss": 3.1398,
      "step": 57000
    },
    {
      "epoch": 0.8,
      "grad_norm": 9.224472045898438,
      "learning_rate": 7.500000000000001e-05,
      "loss": 3.1262,
      "step": 58000
    },
    {
      "epoch": 0.81,
      "grad_norm": 6.980638027191162,
      "learning_rate": 7.426470588235294e-05,
      "loss": 3.1186,
      "step": 59000
    },
    {
      "epoch": 0.82,
      "grad_norm": 6.997853755950928,
      "learning_rate": 7.352941176470589e-05,
      "loss": 3.0849,
      "step": 60000
    },
    {
      "epoch": 0.84,
      "grad_norm": 10.179217338562012,
      "learning_rate": 7.279411764705882e-05,
      "loss": 3.0664,
      "step": 61000
    },
    {
      "epoch": 0.85,
      "grad_norm": 10.887192726135254,
      "learning_rate": 7.205882352941177e-05,
      "loss": 3.0701,
      "step": 62000
    },
    {
      "epoch": 0.86,
      "grad_norm": 8.29320240020752,
      "learning_rate": 7.13235294117647e-05,
      "loss": 3.0555,
      "step": 63000
    },
    {
      "epoch": 0.88,
      "grad_norm": 7.7199320793151855,
      "learning_rate": 7.058823529411765e-05,
      "loss": 3.0374,
      "step": 64000
    },
    {
      "epoch": 0.89,
      "grad_norm": 6.3436713218688965,
      "learning_rate": 6.985294117647059e-05,
      "loss": 3.0284,
      "step": 65000
    },
    {
      "epoch": 0.91,
      "grad_norm": 7.755832195281982,
      "learning_rate": 6.911764705882354e-05,
      "loss": 3.0309,
      "step": 66000
    },
    {
      "epoch": 0.92,
      "grad_norm": 8.789011001586914,
      "learning_rate": 6.838235294117647e-05,
      "loss": 3.0251,
      "step": 67000
    },
    {
      "epoch": 0.93,
      "grad_norm": 11.28974437713623,
      "learning_rate": 6.764705882352942e-05,
      "loss": 3.0054,
      "step": 68000
    },
    {
      "epoch": 0.95,
      "grad_norm": 8.014409065246582,
      "learning_rate": 6.691176470588235e-05,
      "loss": 2.943,
      "step": 69000
    },
    {
      "epoch": 0.96,
      "grad_norm": 7.916352272033691,
      "learning_rate": 6.61764705882353e-05,
      "loss": 2.9593,
      "step": 70000
    },
    {
      "epoch": 0.97,
      "grad_norm": 7.465983867645264,
      "learning_rate": 6.544117647058824e-05,
      "loss": 3.0444,
      "step": 71000
    },
    {
      "epoch": 0.99,
      "grad_norm": 8.596508979797363,
      "learning_rate": 6.470588235294118e-05,
      "loss": 2.9406,
      "step": 72000
    },
    {
      "epoch": 1.0,
      "grad_norm": 7.962533950805664,
      "learning_rate": 6.397058823529412e-05,
      "loss": 2.9536,
      "step": 73000
    },
    {
      "epoch": 1.02,
      "grad_norm": 8.575429916381836,
      "learning_rate": 6.323529411764705e-05,
      "loss": 2.9447,
      "step": 74000
    },
    {
      "epoch": 1.03,
      "grad_norm": 9.913093566894531,
      "learning_rate": 6.25e-05,
      "loss": 2.9276,
      "step": 75000
    },
    {
      "epoch": 1.04,
      "grad_norm": 9.09559154510498,
      "learning_rate": 6.176470588235295e-05,
      "loss": 2.9216,
      "step": 76000
    },
    {
      "epoch": 1.06,
      "grad_norm": 10.370414733886719,
      "learning_rate": 6.102941176470589e-05,
      "loss": 2.9027,
      "step": 77000
    },
    {
      "epoch": 1.07,
      "grad_norm": 8.219986915588379,
      "learning_rate": 6.0294117647058825e-05,
      "loss": 2.9223,
      "step": 78000
    },
    {
      "epoch": 1.08,
      "grad_norm": 8.012933731079102,
      "learning_rate": 5.9558823529411766e-05,
      "loss": 2.8882,
      "step": 79000
    },
    {
      "epoch": 1.1,
      "grad_norm": 7.945128440856934,
      "learning_rate": 5.882352941176471e-05,
      "loss": 2.9212,
      "step": 80000
    },
    {
      "epoch": 1.11,
      "grad_norm": 8.3156099319458,
      "learning_rate": 5.8088235294117656e-05,
      "loss": 2.8888,
      "step": 81000
    },
    {
      "epoch": 1.13,
      "grad_norm": 8.956645011901855,
      "learning_rate": 5.735294117647059e-05,
      "loss": 2.8756,
      "step": 82000
    },
    {
      "epoch": 1.14,
      "grad_norm": 9.642281532287598,
      "learning_rate": 5.661764705882353e-05,
      "loss": 2.8828,
      "step": 83000
    },
    {
      "epoch": 1.15,
      "grad_norm": 7.205311298370361,
      "learning_rate": 5.588235294117647e-05,
      "loss": 2.8659,
      "step": 84000
    },
    {
      "epoch": 1.17,
      "grad_norm": 7.001839637756348,
      "learning_rate": 5.514705882352942e-05,
      "loss": 2.8774,
      "step": 85000
    },
    {
      "epoch": 1.18,
      "grad_norm": 9.188691139221191,
      "learning_rate": 5.441176470588235e-05,
      "loss": 2.8487,
      "step": 86000
    },
    {
      "epoch": 1.19,
      "grad_norm": 10.571969985961914,
      "learning_rate": 5.3676470588235296e-05,
      "loss": 2.8137,
      "step": 87000
    },
    {
      "epoch": 1.21,
      "grad_norm": 15.270223617553711,
      "learning_rate": 5.294117647058824e-05,
      "loss": 2.8193,
      "step": 88000
    },
    {
      "epoch": 1.22,
      "grad_norm": 10.696182250976562,
      "learning_rate": 5.2205882352941185e-05,
      "loss": 2.8554,
      "step": 89000
    },
    {
      "epoch": 1.24,
      "grad_norm": 7.351145267486572,
      "learning_rate": 5.147058823529411e-05,
      "loss": 2.7911,
      "step": 90000
    },
    {
      "epoch": 1.25,
      "grad_norm": 10.928257942199707,
      "learning_rate": 5.073529411764706e-05,
      "loss": 2.8409,
      "step": 91000
    },
    {
      "epoch": 1.26,
      "grad_norm": 10.9475679397583,
      "learning_rate": 5e-05,
      "loss": 2.8137,
      "step": 92000
    },
    {
      "epoch": 1.28,
      "grad_norm": 6.1914544105529785,
      "learning_rate": 4.9264705882352944e-05,
      "loss": 2.883,
      "step": 93000
    },
    {
      "epoch": 1.29,
      "grad_norm": 10.4562406539917,
      "learning_rate": 4.8529411764705885e-05,
      "loss": 2.7984,
      "step": 94000
    },
    {
      "epoch": 1.3,
      "grad_norm": 9.051233291625977,
      "learning_rate": 4.7794117647058826e-05,
      "loss": 2.824,
      "step": 95000
    },
    {
      "epoch": 1.32,
      "grad_norm": 11.021842002868652,
      "learning_rate": 4.705882352941177e-05,
      "loss": 2.7898,
      "step": 96000
    },
    {
      "epoch": 1.33,
      "grad_norm": 9.262455940246582,
      "learning_rate": 4.632352941176471e-05,
      "loss": 2.8125,
      "step": 97000
    },
    {
      "epoch": 1.35,
      "grad_norm": 11.655912399291992,
      "learning_rate": 4.558823529411765e-05,
      "loss": 2.8172,
      "step": 98000
    },
    {
      "epoch": 1.36,
      "grad_norm": 10.774693489074707,
      "learning_rate": 4.485294117647059e-05,
      "loss": 2.7739,
      "step": 99000
    },
    {
      "epoch": 1.37,
      "grad_norm": 9.19642448425293,
      "learning_rate": 4.411764705882353e-05,
      "loss": 2.7366,
      "step": 100000
    },
    {
      "epoch": 1.39,
      "grad_norm": 6.468577861785889,
      "learning_rate": 4.3382352941176474e-05,
      "loss": 2.8233,
      "step": 101000
    },
    {
      "epoch": 1.4,
      "grad_norm": 8.561605453491211,
      "learning_rate": 4.2647058823529415e-05,
      "loss": 2.8192,
      "step": 102000
    },
    {
      "epoch": 1.41,
      "grad_norm": 7.803343296051025,
      "learning_rate": 4.1911764705882356e-05,
      "loss": 2.7455,
      "step": 103000
    },
    {
      "epoch": 1.43,
      "grad_norm": 8.691596031188965,
      "learning_rate": 4.11764705882353e-05,
      "loss": 2.8016,
      "step": 104000
    },
    {
      "epoch": 1.44,
      "grad_norm": 12.206109046936035,
      "learning_rate": 4.044117647058824e-05,
      "loss": 2.7306,
      "step": 105000
    },
    {
      "epoch": 1.46,
      "grad_norm": 9.86367416381836,
      "learning_rate": 3.970588235294117e-05,
      "loss": 2.789,
      "step": 106000
    },
    {
      "epoch": 1.47,
      "grad_norm": 11.271158218383789,
      "learning_rate": 3.897058823529412e-05,
      "loss": 2.7407,
      "step": 107000
    },
    {
      "epoch": 1.48,
      "grad_norm": 8.44462776184082,
      "learning_rate": 3.8235294117647055e-05,
      "loss": 2.7073,
      "step": 108000
    },
    {
      "epoch": 1.5,
      "grad_norm": 8.559765815734863,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 2.7726,
      "step": 109000
    },
    {
      "epoch": 1.51,
      "grad_norm": 8.939220428466797,
      "learning_rate": 3.6764705882352945e-05,
      "loss": 2.7855,
      "step": 110000
    },
    {
      "epoch": 1.52,
      "grad_norm": 8.12287425994873,
      "learning_rate": 3.6029411764705886e-05,
      "loss": 2.7273,
      "step": 111000
    },
    {
      "epoch": 1.54,
      "grad_norm": 9.388208389282227,
      "learning_rate": 3.529411764705883e-05,
      "loss": 2.6875,
      "step": 112000
    },
    {
      "epoch": 1.55,
      "grad_norm": 9.195777893066406,
      "learning_rate": 3.455882352941177e-05,
      "loss": 2.7383,
      "step": 113000
    },
    {
      "epoch": 1.57,
      "grad_norm": 9.30959701538086,
      "learning_rate": 3.382352941176471e-05,
      "loss": 2.6817,
      "step": 114000
    },
    {
      "epoch": 1.58,
      "grad_norm": 8.839010238647461,
      "learning_rate": 3.308823529411765e-05,
      "loss": 2.7706,
      "step": 115000
    },
    {
      "epoch": 1.59,
      "grad_norm": 9.84619140625,
      "learning_rate": 3.235294117647059e-05,
      "loss": 2.7089,
      "step": 116000
    },
    {
      "epoch": 1.61,
      "grad_norm": 7.115070819854736,
      "learning_rate": 3.161764705882353e-05,
      "loss": 2.6872,
      "step": 117000
    },
    {
      "epoch": 1.62,
      "grad_norm": 9.583109855651855,
      "learning_rate": 3.0882352941176475e-05,
      "loss": 2.7418,
      "step": 118000
    },
    {
      "epoch": 1.63,
      "grad_norm": 9.215043067932129,
      "learning_rate": 3.0147058823529413e-05,
      "loss": 2.7477,
      "step": 119000
    },
    {
      "epoch": 1.65,
      "grad_norm": 10.684328079223633,
      "learning_rate": 2.9411764705882354e-05,
      "loss": 2.6909,
      "step": 120000
    },
    {
      "epoch": 1.66,
      "grad_norm": 9.219472885131836,
      "learning_rate": 2.8676470588235295e-05,
      "loss": 2.6756,
      "step": 121000
    },
    {
      "epoch": 1.68,
      "grad_norm": 9.242525100708008,
      "learning_rate": 2.7941176470588236e-05,
      "loss": 2.7067,
      "step": 122000
    },
    {
      "epoch": 1.69,
      "grad_norm": 7.53745698928833,
      "learning_rate": 2.7205882352941174e-05,
      "loss": 2.6575,
      "step": 123000
    },
    {
      "epoch": 1.7,
      "grad_norm": 11.90846061706543,
      "learning_rate": 2.647058823529412e-05,
      "loss": 2.7008,
      "step": 124000
    },
    {
      "epoch": 1.72,
      "grad_norm": 11.04818344116211,
      "learning_rate": 2.5735294117647057e-05,
      "loss": 2.6729,
      "step": 125000
    },
    {
      "epoch": 1.73,
      "grad_norm": 8.106480598449707,
      "learning_rate": 2.5e-05,
      "loss": 2.6733,
      "step": 126000
    },
    {
      "epoch": 1.74,
      "grad_norm": 8.744349479675293,
      "learning_rate": 2.4264705882352942e-05,
      "loss": 2.6257,
      "step": 127000
    },
    {
      "epoch": 1.76,
      "grad_norm": 8.591511726379395,
      "learning_rate": 2.3529411764705884e-05,
      "loss": 2.6735,
      "step": 128000
    },
    {
      "epoch": 1.77,
      "grad_norm": 11.799189567565918,
      "learning_rate": 2.2794117647058825e-05,
      "loss": 2.6436,
      "step": 129000
    },
    {
      "epoch": 1.78,
      "grad_norm": 10.149810791015625,
      "learning_rate": 2.2058823529411766e-05,
      "loss": 2.6848,
      "step": 130000
    },
    {
      "epoch": 1.8,
      "grad_norm": 8.766207695007324,
      "learning_rate": 2.1323529411764707e-05,
      "loss": 2.6579,
      "step": 131000
    },
    {
      "epoch": 1.81,
      "grad_norm": 13.582180976867676,
      "learning_rate": 2.058823529411765e-05,
      "loss": 2.6792,
      "step": 132000
    },
    {
      "epoch": 1.83,
      "grad_norm": 8.492212295532227,
      "learning_rate": 1.9852941176470586e-05,
      "loss": 2.6825,
      "step": 133000
    },
    {
      "epoch": 1.84,
      "grad_norm": 9.979695320129395,
      "learning_rate": 1.9117647058823528e-05,
      "loss": 2.6332,
      "step": 134000
    },
    {
      "epoch": 1.85,
      "grad_norm": 9.18397045135498,
      "learning_rate": 1.8382352941176472e-05,
      "loss": 2.624,
      "step": 135000
    },
    {
      "epoch": 1.87,
      "grad_norm": 8.247825622558594,
      "learning_rate": 1.7647058823529414e-05,
      "loss": 2.6324,
      "step": 136000
    },
    {
      "epoch": 1.88,
      "grad_norm": 10.466139793395996,
      "learning_rate": 1.6911764705882355e-05,
      "loss": 2.64,
      "step": 137000
    },
    {
      "epoch": 1.89,
      "grad_norm": 8.848756790161133,
      "learning_rate": 1.6176470588235296e-05,
      "loss": 2.6722,
      "step": 138000
    },
    {
      "epoch": 1.91,
      "grad_norm": 10.188443183898926,
      "learning_rate": 1.5441176470588237e-05,
      "loss": 2.6219,
      "step": 139000
    },
    {
      "epoch": 1.92,
      "grad_norm": 8.88583755493164,
      "learning_rate": 1.4705882352941177e-05,
      "loss": 2.6098,
      "step": 140000
    },
    {
      "epoch": 1.94,
      "grad_norm": 10.230560302734375,
      "learning_rate": 1.3970588235294118e-05,
      "loss": 2.5964,
      "step": 141000
    },
    {
      "epoch": 1.95,
      "grad_norm": 9.804787635803223,
      "learning_rate": 1.323529411764706e-05,
      "loss": 2.6625,
      "step": 142000
    },
    {
      "epoch": 1.96,
      "grad_norm": 8.073710441589355,
      "learning_rate": 1.25e-05,
      "loss": 2.6075,
      "step": 143000
    },
    {
      "epoch": 1.98,
      "grad_norm": 12.808731079101562,
      "learning_rate": 1.1764705882352942e-05,
      "loss": 2.6007,
      "step": 144000
    },
    {
      "epoch": 1.99,
      "grad_norm": 8.594094276428223,
      "learning_rate": 1.1029411764705883e-05,
      "loss": 2.6796,
      "step": 145000
    },
    {
      "epoch": 2.0,
      "grad_norm": 7.6602654457092285,
      "learning_rate": 1.0294117647058824e-05,
      "loss": 2.5903,
      "step": 146000
    },
    {
      "epoch": 2.02,
      "grad_norm": 7.795215129852295,
      "learning_rate": 9.558823529411764e-06,
      "loss": 2.6169,
      "step": 147000
    },
    {
      "epoch": 2.03,
      "grad_norm": 12.642619132995605,
      "learning_rate": 8.823529411764707e-06,
      "loss": 2.6052,
      "step": 148000
    },
    {
      "epoch": 2.05,
      "grad_norm": 11.36617374420166,
      "learning_rate": 8.088235294117648e-06,
      "loss": 2.5799,
      "step": 149000
    },
    {
      "epoch": 2.06,
      "grad_norm": 8.55701732635498,
      "learning_rate": 7.3529411764705884e-06,
      "loss": 2.5912,
      "step": 150000
    },
    {
      "epoch": 2.07,
      "grad_norm": 8.376766204833984,
      "learning_rate": 6.61764705882353e-06,
      "loss": 2.6053,
      "step": 151000
    },
    {
      "epoch": 2.09,
      "grad_norm": 7.6095452308654785,
      "learning_rate": 5.882352941176471e-06,
      "loss": 2.5849,
      "step": 152000
    },
    {
      "epoch": 2.1,
      "grad_norm": 6.460384368896484,
      "learning_rate": 5.147058823529412e-06,
      "loss": 2.5777,
      "step": 153000
    },
    {
      "epoch": 2.11,
      "grad_norm": 10.059796333312988,
      "learning_rate": 4.411764705882353e-06,
      "loss": 2.5864,
      "step": 154000
    },
    {
      "epoch": 2.13,
      "grad_norm": 8.668951034545898,
      "learning_rate": 3.6764705882352942e-06,
      "loss": 2.6189,
      "step": 155000
    },
    {
      "epoch": 2.14,
      "grad_norm": 12.33484172821045,
      "learning_rate": 2.9411764705882355e-06,
      "loss": 2.5734,
      "step": 156000
    },
    {
      "epoch": 2.16,
      "grad_norm": 10.803686141967773,
      "learning_rate": 2.2058823529411767e-06,
      "loss": 2.6202,
      "step": 157000
    },
    {
      "epoch": 2.17,
      "grad_norm": 9.455333709716797,
      "learning_rate": 1.4705882352941177e-06,
      "loss": 2.5897,
      "step": 158000
    },
    {
      "epoch": 2.18,
      "grad_norm": 10.68264389038086,
      "learning_rate": 7.352941176470589e-07,
      "loss": 2.5906,
      "step": 159000
    },
    {
      "epoch": 2.2,
      "grad_norm": 8.932113647460938,
      "learning_rate": 0.0,
      "loss": 2.5886,
      "step": 160000
    }
  ],
  "logging_steps": 1000,
  "max_steps": 160000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 160000,
  "total_flos": 1.2222531518985216e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
